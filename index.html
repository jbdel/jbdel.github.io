<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr" >
    <head>
        <title>Jean-Benoit Delbrouck</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <meta name="author" content="Jean-Benoit Delbrouck" />
        <meta name="keywords" content="Jean-Benoit, Delbrouck, NLP, Neural machine translation, multimodal interfaces, interaction, cognition, robotics" />
        <meta name="description" content="Jean-Benoit Delbrouck" />
        <meta name="robots" content="all" />

        <link rel="shortcut icon" href="https://www-media.stanford.edu/assets/favicon/favicon-128.png" type="image/x-icon" />



        <style>
        body{
        font-family: Verdana,Arial, Helvetica, sans-serif;
            font-size: 11px;
            color: black;
        }

        #papers li{
            margin-bottom:10px;
        }

        a:link       { color: blue;   text-decoration: underline; }
        a:visited    { color: blue; text-decoration: none;      }


        </style>

        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js" type="text/javascript"></script>
        <script>
                $(function () {
                    var $element = $('.highlight1');
                    setInterval(function () {
                        $element.fadeIn(1000, function () {
                            $element.fadeOut(1500, function () {
                                $element.fadeIn(1500)
                            });
                        });
                    }, 750);
                });
        </script>

    </head>
<body>
<p>
<img src="img/fpms_logo.png" height="50px" /> &nbsp;  &nbsp; &nbsp;
<img src="img/stanford_logo.png" height="50px" /></p>


 <fieldset style="width:30%">
              <legend>Infos</legend>


<img src="img/jb.jpeg" width="100px" style="float:left;margin-right:5px;">
Name : Jean-Benoit Delbrouck<br/>
Email : Jean-Benoit.delbrouck [at] umons.ac.be<br/>
Phone : +32 (0) 65 37 47 70<br/>
Adress : TCTS Lab - 31, Boulevard Dolez, MONS, Belgium<br/><br/>
Thesis : Grounded and Pragmatics Learning for Situated Human-Robot Interactions and Understanding
</fieldset>

 <fieldset style="width:30%">
              <legend>Publications</legend>

	 
 2020

 <ul id="papers">
	 <li>J.B. Delbrouck, N. Tits, S. Dupont. Modulated Fusion using Transformer for Linguistic-Acoustic Emotion Recognition
		<a href="https://www.aclweb.org/anthology/2020.nlpbt-1.1/">[Link]</a>
		<a href="https://www.aclweb.org/anthology/2020.nlpbt-1.1.bib">[bib]</a>	
		<a href="https://github.com/jbdel/MOSEI_UMONS">[Code]</a>
		- <b>First International Workshop on Natural Language Processing Beyond Text, EMNLP 2020, Online</b>
		
	</li>
	 
	<li>J.B. Delbrouck, N. Tits, M. Brousmiche, S. Dupont. A Transformer-based joint-encoding for Emotion Recognition and Sentiment Analysis
		<i style="color:red;"> Challenge 1st place and best Paper Award</i>
		<a href="https://www.aclweb.org/anthology/2020.challengehml-1.1/">[Link]</a>
		<a href="https://www.aclweb.org/anthology/2020.challengehml-1.1.bib">[bib]</a>	
		<a href="https://github.com/jbdel/MOSEI_UMONS">[Code]</a>
		- <b>Second Grand-Challenge and Workshop on Multimodal Language, ACL 2020, Seattle, USA</b>
		
	</li>
</ul>
	 
 2019

 <ul id="papers">
	<li>J.B. Delbrouck, S. Dupont. Adversarial reconstruction for Multi-modal Machine Translation
		<i style="color:red;">
		<a href="https://arxiv.org/abs/1910.02766">[Link]</a>
		<a href="">[bib]</a>
		</i>
	</li>

	<li>J.B. Delbrouck, Vanderplaetse B., S. Dupont. Modulated Self-attention Convolutional Network for VQA
		<i style="color:red;">
		<a href="">[Link]</a>
		<a href="">[bib]</a>
		</i>
		- <b>ViGiL Workshop, NeurIPS 2020, Vancouver, Canada</b>
	</li>

	<li>J.B. Delbrouck, S. Dupont. Can adversarial training learn image captioning ?
		<i style="color:red;">
		<a href="">[Link]</a>
		<a href="">[bib]</a>
		<a href="https://github.com/bastienvanderplaetse/gan-image-captioning">[Code]</a>
		</i>
		- <b>ViGiL Workshop, NeurIPS 2020, Vancouver, Canada</b>
	</li>


</ul>

 2018
<ul id="papers">
	<li>J.B. Delbrouck, S. Dupont. Umons submission for wmt18 multimodal translation task
		<i style="color:red;"> Challenge 1st place</i>
<a href="http://statmt.org/wmt18/pdf/WMT071.pdf">[Link]</a>
<a href="http://statmt.org/wmt18/bib/WMT071.bib">[bib]</a>
<a href="https://github.com/jbdel/WMT18_MNMT">[Code]</a>
- <b>Proceedings of the Third Conference on Machine Translation, Brussels, Belgium</b>
	</li>

		<li>J.B. Delbrouck, S. Dupont. Object-oriented Targets for Visual Navigation using Rich Semantic Representations
<i style="color:red;">
<a href="https://nips2018vigil.github.io/static/papers/accepted/15.pdf">[Link]</a>
<a href="">[bib]</a>
</i>
- <b>ViGiL Workshop, NIPS 2019, Montreal, Canada</b>
	</li>


</ul>

2017
<ul id="papers">



<li>J.B. Delbrouck, S. Dupont. Modulating and attending the source image during encoding improves Multimodal Translation
<i style="color:red;">
<a href="https://arxiv.org/pdf/1712.03449">[Link]</a>
<a href="">[bib]</a>
</i>
- <b>NIPS, Long Beach, CA, USA</b>
</li>


<li>J.B. Delbrouck, S. Dupont, O. Seddati. Visually Grounded Word Embeddings and Richer Visual Features for Improving Multimodal Neural Machine Translation 
<i style="color:red;">
<a href="http://www.isca-speech.org/archive/GLU_2017/pdfs/GLU2017_paper_15.pdf">[Link]</a>
<a href="http://www.isca-speech.org/archive/GLU_2017/abstracts/GLU2017_paper_15.html">[bib]</a>
</i>
- <b>Interspeech, Stockholm, Sweden</b>
</li>

<li>J.B. Delbrouck, S. Dupont. An empirical study on the effectiveness of images in Multimodal Neural Machine Translation 
<i style="color:red;">
<a href="http://www.aclweb.org/anthology/D/D17/D17-1095.pdf">[Link]</a>
<a href="http://www.aclweb.org/anthology/D/D17/D17-1095.bib">[bib]</a>
</i> 
- <b>EMNLP, Copenhagen, Denmark</b>
</li>

<li>J.B. Delbrouck, S. Dupont. Multimodal Compact Bilinear Pooling for Multimodal Neural Machine Translation 
<i style="color:red;"><a href="https://arxiv.org/pdf/1703.08084.pdf">[Link]</a>
<a href="http://dblp.uni-trier.de/rec/bibtex/journals/corr/DelbrouckD17">[bib]</a>
<a href="https://github.com/jbdel/mmt_cbn">[Code]</a>
</i> 
</li>
</ul>

<p><b>Miscellaneous reports</b></p>

- Transformer for Emotion Recognition (2018) 
<i style="color:red;"><a href="https://arxiv.org/pdf/1805.02489">[Link]</a></i>
<a href="https://github.com/jbdel/OMG_UMONS_submission">[Code]</a><br/>

- An RNN-Based Multimodal Sentiment Analysis: Focusing on Facial Expressions and Multimodal Dynamic Representations (2017) 
<i style="color:red;"><a href="papers/rnn-based-multimodal.pdf">[Link]</a></i>
<a href="https://github.com/jbdel/MM_sentiment_RNN">[Code]</a><br/>

</fieldset>

  <fieldset style="width:30%">
              <legend>Miscellaneous Codes and paper implementation</legend>

Image Reconstruction for Visual Question Answering <a href="https://github.com/jbdel/vqa_rec">[Code]</a><br/>
Bottom-up Visual Question Answering using ResNet <a href="https://github.com/numediart/Visual-Question-Answering">[Code]</a>



</fieldset>


 <fieldset style="width:30%">
              <legend>Teaching</legend>

<b>Lecturer</b>
<ul>
<li>Artificial Intelligence - Haute école Léonard de Vinci (BA3) <a href="teaching/index.html">[Syllabus]</a></li>
<li>Signal Processing - Polytechnic Mons (MA1) <a href="teaching/SP/TraitSig.pdf">[Syllabus]</a> <a href="teaching/index.html">[My notes]</a></li>
<li>Databases - Haute école Léonard de Vinci (BA2)</li>
<li>Data Structures - Haute école Léonard de Vinci (BA1)</li>
</ul>

<b>Jurys</b>

<ul>
<li>President - June 2018 - Haute école Léonard de Vinci</li>
<li>President - June 2018 - Haute école Léonard de Vinci</li>
<li>June 2018 - Polytechnic Mons</li>
<li>June 2017 - Haute école Léonard de Vinci</li>
</ul>

<b>Projects</b><br/>
     <p> >> <a href="projects/index.html"><span class="highlight1">Click here to see available projects (MA1 and MA2)</span></a> << </p>

2017 -

<ul>
<li>Jason Bury - Reinforcement Learning in Games (MA2) </li>
<li>Arnaud Vella - Automatic image captionning using AI (MA1)</li>
<li>Robin Jacobs - Expressive robot to its environement (MA2)</li>
</ul>

</fieldset>


 <fieldset style="width:30%">
              <legend>Meetings</legend>

2018 -
<ul>
<li><a href="http://www.chistera.eu/">CHIST-ERA</a> HLU Master Class - <b>Paris, France</b></li>
</ul>
2017 - 
<ul>
<li>eNTERFACE'17 - <b>Porto, Portugal</b></li>
<li>International Summer School on Deep Learning 2017 - <b>Bilbao, Spain</b></li>
<li><a href="http://www.chistera.eu/">CHIST-ERA</a> Annual meeting'17 - <b>Bruxelles, Belgium</b></li>
</ul>
</fieldset>




</body>


</html>
